\documentclass[11pt]{article}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage[margin=1.25in]{geometry}

\newcommand{\eq}[1]{Eq.~(\ref{#1})}
\newcommand{\Eq}[1]{Equation~(\ref{#1})}
\begin{document}

\title{A crash course in population genetics}
\author{Benjamin Good}

\maketitle

% wright-fisher model is infinite expansion bottlenecking!

\section{Introduction}

In the future, there will be an introduction here (i.e., what we're doing, what knowledge is assumed, what we hope to get out of theoretical models). But for now, nothing. 

\section{Single-locus dynamics} 

\noindent Let $f$ be the fraction of individuals in the population with a particular genotype. This is variously referred to as the gene/genotype/allele frequency. We start by considering the simplest possible model for the time evolution of $f$, where we compete the genotype of interest against a uniform reference genotype and neglect the effects of future mutations. In the population genetics literature, this is known as a \emph{single-locus} model, since it also approximates the evolution of a binary genome of length $L=1$. Departing from the standard convention, we will define our simplest model as a stochastic differential equation, 
\begin{align}
\label{eq:single-locus-langevin}
\frac{\partial f}{\partial t} = \underbrace{s f(1-f)}_\text{selection} + \underbrace{\sqrt{\frac{f(1-f)}{N}} \eta(t)}_\text{genetic drift} \, ,
\end{align}
where $\eta(t)$ is a Brownian noise term with lowest order moments $\langle \eta(t) \rangle = 0$ and $\langle \eta(t) \eta(t') \rangle = \delta(t-t')$. In the physics literature, this is known as a \emph{Langevin equation}. The interpretation of these Langevin dynamics is that in some infinitesimal time $dt$,
\begin{align}
\label{eq:ito-interpretation}
f(t+dt) = f(t) + dt \left[ s f(t)(1-f(t)) \right] + \sqrt{dt} \sqrt{\frac{f(t)(1-f(t))}{N}} \eta(t) \, .
\end{align} 
where $\eta(t)$ is a Gaussian random variable that is independent of $f(t)$\footnote{In physics/math language, \eq{eq:ito-interpretation} is known as the Ito interpretation of the stochastic ODE, as opposed to the alternative Stratanovich interpretation.}.

\paragraph{Problem 1.} Derive equations of motion for the first two moments of $f(t)$. This is an example of ``moment hell.'' What condition needs to be satisfied in order for the moment hierarchy to close? What are the time-dependent solutions?

\paragraph{Solution.}
\begin{subequations}
\begin{align}
\frac{\partial \langle f \rangle}{\partial t} & = s \langle f \rangle - s \langle f^2 \rangle \\
\frac{\partial \langle f^2 \rangle}{\partial t} & = 2 s \langle f^2 \rangle - 2 s \langle f^3 \rangle + \frac{\langle f \rangle-\langle f^2 \rangle}{N} 
\end{align}
\end{subequations} 
These equations are solvable when $s=0$. The solutions are
\begin{subequations}
\begin{align}
\langle f \rangle & = p \\
\langle f^2 \rangle & = p \left[ 1 - e^{-t/N} \right] + p^2 e^{-t/N} 
\end{align}
\end{subequations}

\paragraph{Problem 2.} Let $\phi(f,t)$ denote the probability distribution of $f$ at time $t$. Derive the Fokker-Planck equation (i.e., the forward Kolmogorov equation) governing the evolution of $\phi$. 

\paragraph{Solution.} 
\begin{align}
\frac{\partial \phi}{\partial t} = - \frac{\partial}{\partial f} \left[ s f(1-f) \phi \right] + \frac{1}{2N} \frac{\partial^2}{\partial f^2} \left[ f(1-f) \phi \right]
\end{align}

\paragraph{Problem 3.} Derive the partial differential equation governing the evolution of the moment generating function $H(z,t) = \langle e^{-zf(t)} \rangle$. First, convince yourself that this is given by the Laplace transform of the equation for $\phi(f,t)$. Next, see if you can derive this directly from the Langevin dynamics in \eq{eq:single-locus-langevin}. 

\paragraph{Solution}
\begin{align}
\frac{\partial H}{\partial t} = - \left[ - s z + \frac{z^2}{2N} \right] \left[ \frac{\partial H}{\partial z} + \frac{\partial^2 H}{\partial z^2} \right] 
\end{align}

\noindent \Eq{eq:single-locus-langevin} is difficult to solve in closed form. This is difficulty is is primarily due to the fact that \eq{eq:single-locus-langevin} contains both a stochastic component ($\eta$) and a nonlinear component ($f(1-f)$). Note that since the expectation of $\eta$ vanishes, the $f(1-f)$ factor in the drift term is only ``pseudo-nonlinear,'' in that it only influences moments of similar order. As we saw in Problem 1, the nonlinear selection term is far more problematic, since it leads to a moment hierarchy that does not close.

Fortunately, it is often the case in nature that population sizes are very large and selection differences are very small. It is therefore likely that the product $Ns$ is either very large or very small, unless there is some additional constraint that we have not accounted for. Thus, rather than trying to obtain a complete solution for arbitrary $Ns$, we will be satisfied with \emph{asymptotic} solutions in the $Ns \to 0$ and $Ns \to \infty$ limits. In the $Ns \to 0$ limit, we can neglect the selection term entirely, which leads to the well-known \emph{neutral theory} of population genetics. We'll ignore this case for now, but we'll come back to it in a later section.

In the $Ns \to \infty$ limit, it is tempting to drop the genetic drift term completely (i.e., make a \emph{deterministic approximation}), but this is not always valid. In particular, we see that the drift term is only neglgible compared to the selection term when $Ns f(1-f) \gg 1$, so the deterministic approximation breaks down when $f$ approaches $0$ or $1$. Fortunately, the nonlinear terms become negligible in this limit, and we can decompose the dynamics of $f$ into the piecewise form
\begin{align}
\frac{\partial f}{\partial t} & = \begin{cases}
s(1-f) f + \sqrt{\frac{1-f}{N}} \eta & \text{if $1-f \ll 1$,} \\
s f(1-f) & \text{if $Ns f(1-f) \gg 1$} \\
s f + \sqrt{\frac{f}{N}} \eta & \text{if $f \ll 1$}
\end{cases}
\end{align}

\paragraph{Problem 4.} Solve the initial value problem $\partial_t f = sf(1-f)$ with $f(0) = p$. 

\paragraph{Solution.}
\begin{align}
f(t) = \frac{p e^{st}}{1+p \left( e^{st}-1 \right)} 
\end{align}

\paragraph{Problem 5.} Solve the initial value problem $\partial_t f = s f + \sqrt{f/N} \eta$ with $f(0) = p$. Since $f$ is a random variable, you'll need to solve for the generating function $H(z,t) = \langle e^{-z f(t) } \rangle$, which will require you to use the \emph{method of characteristics} (see Appendix for a short primer).

\paragraph{Solution.} 
\begin{align}
H(z,t) = \exp \left[ - \frac{p z e^{st}}{1+\frac{z}{2Ns} \left( e^{st} - 1 \right)} \right]
\end{align}

\paragraph{Problem 6.} In the initial value problem above, what is the probability that $f$ eventually goes extinct, i.e., what is the probability that $f=0$ when $t \to \infty$. What about the initial value problem before it?

\paragraph{Solution.}
In the IVP from problem 6, we have
\begin{align}
p_\mathrm{ext} = \begin{cases}
e^{-2Nsp} & \text{if $s > 0$.} \\
1 & \text{if $s < 0$.}
\end{cases}
\end{align}
In the IVP from problem 5, we have
\begin{align}
p_\mathrm{ext} = \begin{cases}
0 & \text{if $s > 0$.} \\
1 & \text{if $s < 0$.}
\end{cases}
\end{align}

\paragraph{Asymptotic matching.}  Now that we have solutions for the deterministic and linear regimes of \eq{eq:single-locus-langevin}, we can think about how to patch the two regimes together. This is necessary if we want to ask how a new mutatation (which starts out at frequency $p=1/N$) rises to detectable frequencies in the population. Now is the point where the $Ns \gg 1$ assumption comes in. Let's define a frequency scale $f^* = 1/\sqrt{Ns}$. By construction, we have $Ns f(1-f) \sim \sqrt{Ns} \gg 1$, so the genetic drift term is negligible. At the same time, $f^* \ll 1$, so the nonlienar terms are negligible as well. Thus, when $f \sim f^*$, we have an \emph{overlap} regime where both the deterministic and linear approximations are valid and
\begin{align}
\frac{\partial f}{\partial t} = s f \, \quad \to \quad f(t) = f(t_0) e^{s(t-t_0)}  \, , \quad p_\mathrm{ext} = \begin{cases}
0 & \text{if $s > 0$} \\
1 & \text{if $s < 0$}
\end{cases}
\end{align}
To this end, let's define a new random variable $\nu$, such that $f(t) = \frac{\nu(t)}{2Ns} e^{st}$. Due to the overlap argument above, we expect that at long times, the distribution of $\nu(t)$ becomes independent of time, $\nu(t) \to \nu$. We can see this explicitly by substituting into the generating function for $f(t)$:
\begin{align}
H_{\nu}(z,t) = \left\langle e^{-z \nu(t)} \right\rangle = \left\langle e^{-2Ns e^{-st} z f(t)} \right\rangle = H_f(2Nse^{-st}z,t) 
\end{align}

\paragraph{Problem 7.} Suppose that $s > 0$ and $p=1/N$. Calculate the generating function for $\nu$ (i.e., $\nu(\infty)$). What is the average value $\langle \nu \rangle$?

\paragraph{Solution.}  
\begin{align}
H_\nu(z) = \lim_{t \to \infty} H(2 Ns e^{-st} z ,t) = 1 - \frac{2s z}{1+z}  
\end{align}

\paragraph{Problem 8.} Calculate the distribution of $\nu$, conditioned on $\nu > 0$. What is the average value $\langle \nu | \nu > 0 \rangle$?

\paragraph{Solution.}

\begin{align}
H_{\nu}(z|\nu>0) = \left( 1 + z \right)^{-1}
\end{align}
which is an exponential distribution with mean $\langle \nu | \nu > 0 \rangle = 1$. 

\noindent \newline Thus, we see that the frequency of a successful beneficial mutation (at ``long'' times) is given by
\begin{align}
f(t) = \frac{\frac{\nu}{2Ns} e^{st}}{1+\frac{\nu}{2Ns} e^{st}}
\end{align}
where $\nu$ captures all of the stochastic dependence from the linear regime. 

\paragraph{Problem 9.} Calculate the expected time for a successful beneficial mutation to rise to frequency $f=0.5$. For comparison, what would the answer be if we had neglected genetic drift from the begining? This shows for a new beneficial mutation, the $Ns \to \infty$ limit is \emph{singular}, i.e., the behavior for large but finite $Ns$ is not simply a small correction to the $Ns = \infty$ solution.  

\paragraph{Solution.} \ldots

\paragraph{Mutations.} If we allow for mutations from mutant to wildtype (ignoring back-mutations for now), this adds an additional term $\mu(1-f)$ to the dynamics of $f$. In most biologically relevant scenarios, $\mu \ll s$, so we can again separate the dynamics of $f$ into three regimes:
\begin{align}
\frac{\partial f}{\partial t} & = s f(1-f) + \mu(1-f) + \sqrt{\frac{f(1-f)}{N}} \eta \\
	& = \begin{cases} 
	s(1-f)+\sqrt{\frac{(1-f)}{N}} \eta(t) & \text{if $1-f \ll 1$} \\
	sf(1-f) & \text{if $Ns f(1-f) \gg 1$} \\
	sf+\mu+\sqrt{\frac{f}{N}} \eta(t) & \text{if $f \ll 1$}
	\end{cases}
\end{align}
Thus, we see that the only real difference is in the linear regime when $f$ is rare. 

\paragraph{Problem 10.} Solve the initial value problem $\partial_t f = s f + \mu + \sqrt{f/N} \eta$ subject to the initial condition $f(0)=0$. 

\paragraph{Solution.}
\begin{align}
H(z,t) = \left[ 1 + \frac{z}{2Ns} \left( e^{st} - 1 \right) \right]^{-2N\mu} 
\end{align}

\paragraph{Problem 11.} In the initial value problem above, calculate the long-time behavior of $f$ when $s>0$. Again, it will be useful to focus on the distribution of $\nu$ defined by $f = \frac{\nu}{2Ns} e^{st}$. Calculate the expected time for this beneficial mutation to reach frequency $f=0.5$. For comparison, what the answer be if we had neglected genetic drift from the begining? 

\paragraph{Solution.} The generating function for $\nu$ is 
\begin{align}
H_\nu(z) = \lim_{t \to \infty} H(2Ns e^{-st} z,t) = (1+z)^{-2N\mu} 
\end{align}

\paragraph{Problem 12.} Calculate the long-time behavior of $f$ when $s < 0$. This is known as \emph{mutation-selection balance}. For comparison, what the answer be if we had neglected genetic drift from the begining (i.e., \emph{deterministic} mutation-selection balance)? Is there a limit in which deterministic selection balance is exact?  

\paragraph{Solution.} When $s < 0$, the generating function for $f$ approaches
\begin{align}
H(z) = \left( 1 + \frac{z}{2N|s|} \right)^{-2N\mu}
\end{align}
which is a standard Gamma distribution with shape parameter $2N\mu$. 

\subsection*{Bonus problems}

In a first pass, it is perfectly fine to skip ahead to the section on multi-locus dynamics. 

\paragraph{Bubble size.} Consider the ``bubble size'' defined by $W(t) = \frac{1}{N} \int_0^t f(t) dt$, where we have inserted the $N^{-1}$ factor in order to ensure that $W(t)$ is unitless. Unlike the other quantities we have considered so far, $W(t)$ is not a Markov random variable, so it is difficult to write down a simple stochastic differential equation for $W(t)$. However, $f(t)$ and $W(t)$ are \emph{jointly} Markov, so we can obtain the dynamics of $W(t)$ by considering the joint generating function
\begin{align}
H(z,\xi,t) \equiv \left\langle e^{-z W(t) - \xi f(t)} \right\rangle
\end{align}
evaluated at $xi=0$. We can again solve this equation using the method of characteristics. In backwards time, the characteristic for $\xi$ satisfies
\begin{align}
\frac{\partial \xi}{\partial \sigma} & = s \xi - \frac{\xi^2}{2N} + \frac{z}{N} \\
\end{align} 
so that 
\begin{align}
\xi(\sigma) = solution
\end{align}
and
\begin{align}
H(z,t) = H(z,\xi=0,t) = e^{-\xi(t) p} 
\end{align}


\paragraph{Problem.} Write down and solve the equations of motion for $H(x,\xi,t)$, subject to the initial condition $W(0)=0$ and $f(0)=N^{-1}$. 

\paragraph{Solution.} To obtain the equations of motion for $W(t)$, we note that there is only a linear contribution from the $W(t)$ term, since the $\sqrt{\delta t}$ integrates out. This yields
\begin{align}
\frac{\partial H}{\partial t} = - \left[ - s \xi + \frac{\xi^2}{2N} - z \right] \frac{\partial H}{\partial \xi}  
\end{align}   

\section{Single-locus dynamics: the heuristic approach}

In the previous section, we attacked the single-locus model using a rigorous\footnote{Here we use the term ``rigorous'' in a physics sense, meaning that our calculations follow from a series of essentially mechanical steps. We do not make any attempt at formal mathematical proofs, which require significantly more notational machinery without providing much additional insight into the biology.} approach based on asymptotic matching. Here, we will re-analyze the same problems using a heuristic approach. To the physicists and mathematicians who are more comfortable with the rigorous derivations, this heuristic analysis may seem a lot less rigorous, and perhaps somewhat redudant. However, this is not actually the case (and it make take several re-readings before this becomes apparent). When done correctly, the heuristic analysis can be viewed as a sort of ``code'' for the more rigorous calculation, which allows us to derive many of the same results up to $\mathcal{O}(1)$ factors. The payoff comes when we try to generalize our analysis to more complicated scenarios. In many cases, the heuristic analysis easily be extended even when the rigorous approach does not yield analytical results.       

To illustrate the heuristic approach, we will consider the fate (i.e., fixation probability) of a new mutation as a function of $N$, $s$, and its initial frequency $f_0$. According to \eq{eq:single-locus-langevin} the change in $f$ due to selection in some infinitesimal time $\delta t$ is given by
\begin{align}
( \delta f )_\mathrm{sel} \sim s  f (1-f) \delta t 
\end{align} 
Thus, it takes roughly $T_\mathrm{sel} = 1/s$ generations for selection to change the frequency of the mutation (or more specifically, its distance from the boundaries at $f=0$ or $f=1$) by a factor of order one. Meanwhile, the change in $f$ due to genetic drift in some infinitesimal time $\delta t$ is given by
\begin{align}
( \delta f)_\mathrm{drift} \sim \mathcal{N}\left(0, \, \frac{f(1-f) \delta t}{N} \right) 
\end{align} 
where $\mathcal{N}(\mu,\sigma^2)$ denotes a normal random variable with mean $\mu$ and variance $\sigma^2$. Thus, it takes roughly $T_\mathrm{drift} = N f(1-f)$ generations to change the frequency of an allele by a factor of order one. We can then compare the two timescales by looking at the ratio 
\begin{align}
\frac{T_\mathrm{drift}}{T_\mathrm{sel}} = N s f(1-f)
\end{align}
When $Ns f (1-f) \gg 1$, the drift timescale is much longer than the selection timescale, and the selective force dominates. On the other hand, when $Ns f(1-f) \ll 1$, the effects of selection can be neglected. Thus, we find that there are two critical frequencies
\begin{align}
f_\mathrm{sel} = \frac{1}{Ns} \, , \quad \tilde{f}_\mathrm{sel} = 1 - \frac{1}{Ns}  
\end{align}
which delineate the boundaries of the effectively neutral and effectively deterministic regimes. When $f \ll f_\mathrm{sel}$ (or when $1-f \ll \tilde{f}_\mathrm{sel}$), the mutation behaves essentially neutrally, while for $f \gg f_\mathrm{sel}$ ($1-f \gg \tilde{f}_\mathrm{sel}$) the frequency evolves deterministically. Note that this is essentially the same argument that we used for the asymptotic matching in the previous section. The difference here is that we will pretend that the two regimes can be extended all the way to $f_\mathrm{sel}$ and $\tilde{f}_\mathrm{sel}$ (i.e., we simply patch them together, rather than asymptotically matching). This will introduce errors that enter as $\mathcal{O}(1)$ factors multiplying various formulae, but otherwise the results will follow exactly as before. 

From this, we can explore several cases. If $Ns \ll 1$, then $f_\mathrm{sel} > 1$ and $\tilde{f}_\mathrm{sel} < 0$, and the neutral regime will apply for the entire range of frequencies. In this case, standard symmetry arguments show that the probability of reaching $f_f$ before hitting $0$ is given by
\begin{align}
p(f_0 \to f_f) = \frac{f_0}{f_f} 
\end{align} 
and the mutation will traverse this distance in a time of order $N (f_f-f_0)$. To find the fixation probability of a new mutation, we set $f_0 = \frac{1}{N}$ and $f_f = 1$, and we find that
\begin{align}
p_\mathrm{fix} = \frac{1}{N} \, , \quad T_\mathrm{fix} \sim N
\end{align}

On the other hand, if $Ns \gg 1$, then $f_\mathrm{sel} \ll 1$, and $1-\tilde{f} \ll 1$, and there will be a broad range of frequencies where selection is the dominant force. Note, however, that genetic drift can never be neglected entirely when considering the fate of a new mutation. Even in infinitely large populations, it is still the case that
\begin{align}
Ns \left( \frac{1}{N} \right) \left( 1 -  \frac{1}{N} \right)  = s \ll 1
\end{align}
so genetic drift always matters early in the life of the mutation. Fortunately, when the mutation is this rare, selection has a negligible effect, and the mutation behaves effectively neutrally. In this case, the mutation rises from $f_0 = \frac{1}{N}$ to $f_\mathrm{sel}$ with probability
\begin{align}
p\left( \frac{1}{N} \to f_\mathrm{sel} \right) = \frac{\frac{1}{N}}{f_\mathrm{sel}} \sim s 
\end{align}
and it takes roughly $1/s$ generations for this to happen. Once the mutation reaches frequency $f_\mathrm{sel}$, selection takes over. If $s < 0$, the mutation will never rise much above $f_\mathrm{sel}$, and will typically go extinct within $1/s$ generations. In other words,
\begin{align}
p_\mathrm{fix} \approx s \cdot 0 \approx 0 \, , \quad T_\mathrm{ext} \approx \frac{1}{s} 
\end{align}
On the other hand, if $s > 0$, then the mutation will start to grow deterministically as
\begin{align}
f(t) = \frac{f_\mathrm{sel} e^{st}}{1+f_\mathrm{sel} ( e^{st} - 1)} 
\end{align} 
and will hit $\tilde{f}_\mathrm{sel}$ after $\frac{2}{s} \log \left( Ns \right)$ generations. At this point, the wildtype allele is essentially deleterious, and will go extinct within $1/s$ generations. Thus, we have
\begin{align}
p_\mathrm{fix} \approx s \cdot 1 \approx 1 \, , \quad T_\mathrm{fix} \approx \frac{2}{s} \log(Ns) 
\end{align}
At this point, accounting for initial frequencies other than $f_0 = \frac{1}{N}$ is straightforward. If $f_0 \gg f_\mathrm{sel}$, then drift will never play an important role, and the mutation will simply fix or go extinct deterministically. On the other hand, if $f_0 \ll f_\mathrm{sel}$, then the mutation will reach frequency $f_\mathrm{sel}$ with probability
\begin{align}
p(f_0 \to f_\mathrm{sel}) \approx N f_0 s
\end{align}
and then fix or go extinct as before. Putting everything together, we find that
\begin{align}
p_\mathrm{fix}(s,N,f_0) \sim \begin{cases}
1 & \text{if $Ns \gg 1$ and $f_0 \gg \frac{1}{Ns}$} \\
N f_0 s & \text{if $Ns \gg 1$ and $f_0 \ll \frac{1}{Ns}$} \\
\frac{f_0}{N} & \text{if $N|s| \ll 1$} \\
0 & \text{if $s < 0$ and $N|s| \gg 1$ and $1-f_0 \gg \frac{1}{Ns}$} \\
1 - N(1-f_0) |s| & \text{if $s < 0$ and $N|s| \gg 1$ and $1-f_0 \ll \frac{1}{Ns}$}
\end{cases}
\end{align}
This can be compared to the exact formula
\begin{align}
p_\mathrm{fix}(s,N,f_0) = \frac{1-e^{-2Ns f_0}}{1-e^{-2Ns}}
\end{align}

\section{Multi-locus dynamics (asexual)}

The preceding single-locus model is valuable because it admits many exact analytical solutions (or at the very least, controlled approximations to the exact solutions). But in reality, genomes always contain more than one site, so at some point we will have to work with a \emph{multi}-locus evolutionary model with more than 2 states (if for no other reason than to examine when the single-locus model provides a good approximation). In principle, it is not hard to derive a generalization of the single-locus dynamics in \eq{eq:single-locus-langevin}. For the moment, we will restrict our attention to asexual organisms so that we can neglect the effects of recombination (we will revisit this case in a later section). Let $G = \{ \vec{g} \}$ denote the set of all possibile genotypes, and let $f(\vec{g})$ denote the frequency of genotype $\vec{g}$. It is straightforward to show that the genotype frequencies evolve according to the Langevin dynamics
\begin{align}
\label{eq:multi-locus-langevin}
\begin{aligned}
\frac{\partial f(\vec{g})}{\partial t} & = \left[ X(\vec{g}) - \overline{X}(t) \right] f(\vec{g}) + \sum_{\vec{g}'} \mu_{\vec{g}' \to \vec{g}} f(\vec{g}') - \mu_{\vec{g} \to \vec{g}'} f(\vec{g}) \\
	& \quad + \sum_{\vec{g}'} \left[ \delta_{\vec{g},\vec{g}'} - f(\vec{g}) \right] \sqrt{\frac{f(\vec{g}')}{N}} \eta(\vec{g}') 
\end{aligned}
\end{align}
where $X(\vec{g})$ is the fitness of genotype $g$, $\overline{X}(t) = \sum_{\vec{g}} X(\vec{g}) f(\vec{g})$ is the mean fitness of the population, and $\mu_{\vec{g} \to \vec{g}'}$ is the mutation rate between genotype $\vec{g}$ and $\vec{g}'$. The easiest way to show this is by considering stochastic model in which
\begin{align}
f(\vec{g},t+dt) \propto f(\vec{g}) + dt \left[ X(\vec{g}) + \sum_{\vec{g}'} \mu_{\vec{g}' \to \vec{g}} f(\vec{g}') - \mu_{\vec{g} \to \vec{g}'} f(\vec{g}) \right] + \sqrt{\frac{f(\vec{g}) dt}{N}} \eta(\vec{g}) 
\end{align}
where the constant of proportionality is set by the normalization condition $\sum_{\vec{g}} f(\vec{g},t+dt) = 1$. In principle, one can analyze \eq{eq:multi-locus-langevin} in much the same way that we analyzed \eq{eq:single-locus-langevin} above. In practice, however, this is difficult to make any progress without making further simplifying assumptions about the genotype to fitness map $X(\vec{g})$ and the structure of the genotype mutation network $\mu_{\vec{g} \to \vec{g}'}$. Both of these quantities are in principle quite complicated, and whole subfields of biology are devoted to measuring them empirically. Here, we'll focus on one of the simplest possible ``null models,'' which is designed to mimic a long sequence of nucleic acids. Suppose that the genome consists of $L$ sites, each of which can be in one of two states (traditionally denoted by $0$ and $1$ for the wildtype and mutant alleles, respectively). Then each genotype can be represented by an $L$-dimensional vector
\begin{align}
\vec{g} = \underbrace{(0,1,1,0,\ldots,0,1) }_{L} 
\end{align}
we assume that mutations happen at each site independently, so that $\mu_{\vec{g} \to \vec{g}'} > 0$ only if $\vec{g}$ and $\vec{g}'$ differ by a single ``bit-flip.'' We assume that the fitness contribution for each site is additive additive, so that 
\begin{align}
X(\vec{g}) = \sum_{i=1}^{L} s_i g_i \, , 
\end{align}
for some collection of \emph{fitness effects} $\{ s_i \}$. On the surface, these assumptions do not appear to produce any major simplifications in \eq{eq:multi-locus-langevin}, and the general version of this model becomes increasingly intractable as $L$ increases. The central problem is that the number of possible genotypes is often incredibly large, so that only a finite number of genotypes will be occupied in any finite population. This leads to a type of replica symmetry breaking, where the genotype frequencies in any particular population deviate dramatically from the ensemble average.  

Fortunately, while the general form of this model is intractable for finite $L$, it turns out that we can make significant progress by focusing on the \emph{infinite sites limit} where  $L \to \infty$ and $\mu \to 0$. In this model, two genotypes with the same fitness are completely equivalent, both in terms of their present reproductive capacity and their potential for future mutations. Thus, we can coarse-grain over the underlying genotypes and work directly with the \emph{fitness classes}, $f(X) = \sum_{\vec{g} : X(\vec{g}) = X} f(\vec{g})$. The underlying mutation network can be coarse-grained to a \emph{distribution of fitness effects}, $U \rho(s) = \frac{1}{|G|} \sum_{\vec{g},\vec{g}': X(\vec{g}') = X(\vec{g})+s} \mu_{\vec{g} \to \vec{g}'}$, and the coarse-grained Langevin dynamics are given by  
\begin{align}
\label{eq:fitness-class-langevin}
\begin{aligned}
\frac{\partial f(X)}{\partial t} & = \left[ X-\overline{X}(t) \right] f(X) + U \int \rho(s) \left[ f(X-s) - f(X) \right] \, ds \\
	& \quad + \sum_{X'} \left[ \delta_{XX'} - f(X) \right] \sqrt{\frac{f(X')}{N}} \eta(X')   
\end{aligned}
\end{align}
The advantage of this ``mesoscopic'' level of description is that the fitness distribution can be highly predictable even when the underyling genotypes are highly stochastic (i.e., the replica symmetry breaking is less severe). 

\subsection*{Deterministic mutation-selection balance}

Motivated by the deterministic mutation-selection balance in the single-locus case, we can try to seek a solution of \eq{eq:fitness-class-langevin} in the infinite population limit where the effects of genetic drift can be neglected, and 
\begin{align}
\label{eq:deterministic-fitness-distribution}
\frac{\partial f(X)}{\partial t} & = \left[ X-\overline{X}(t) \right] f(X) + U \int \rho(s) \left[ f(X-s) - f(X) \right] \, ds 
\end{align}
At first glance, the nonlinearity in the selection term appears problematic, but this nonlinearity can be eliminated by first solving for the unconstrained frequencies
\begin{align}
\label{eq:deterministic-fitness-distribution}
\frac{\partial g(X)}{\partial t} & = X g(X) + U \int \rho(s) \left[ g(X-s) - g(X) \right] \, ds 
\end{align}
and then normalizing, $f(X) = g(X) / \sum_X g(X)$. 

\paragraph{Problem} Verify that $f(X) = g(X) / \sum_X g(X)$ satisfies \eq{eq:deterministic-fitness-distribution}. 

\paragraph{Problem} Solve the initial value problem in \eq{eq:f-equation} subject to the initial condition $f(X,0) = \delta(X)$. The easiest way to do this is to solve for the Laplace transform $\tilde{f}(z,t) = \int f(X,t) e^{-z X} \, dX$. 

\paragraph{Solution}

\paragraph{Problem} From the solution of the IVP above, derive an expression for the mean and variance of the fitness distribution, defined by
\begin{align}
\overline{X}(t) & = \int X f(X,t) \, dX \\
\sigma^2(t) & = \int \left[ X-\overline{X}(t) \right]^2  f(X,t) \, dX
\end{align}

\paragraph{Solution}

Mention singularity of the beneficial case. Non-singularity of the deleterious case. 

\paragraph{Problem} Consider the case where all mutations have the same deleterious fitness cost $s$, so that $\rho(x) = \delta(x+s)$. Invert $\tilde{f}(z,t)$ to obtain $f(X,t)$. The easiest way to do this is to change variables from fitness ($X$) to the number of deleterious mutations ($k = -X/s$). What is the long time limit? This is the classic deleterious mutation-selection balance first derived by Haigh (1978). What are the equilibrium values of $\overline{X}$ and $\sigma^2$? What is the relaxation time to this equilibrium solution? 

\paragraph{Solution} 
The time-dependent solution is
\begin{align}
f(k,t) = \frac{\left[ \frac{U}{s} \left( 1 - e^{-st} \right) \right]^k}{k!} \exp \left[ - \frac{U}{s} \left( 1 - e^{-st} \right) \right] \, ,
\end{align}
which approaches the equilibrium distribution,
\begin{align}
f(k) = \frac{\left(\frac{U}{s}\right)^k}{k!} e^{-U/s} \, ,
\end{align}
on the timescale $t_{eq} \sim 1/s$. The mean and variance of the equilibrium distribution are given by
\begin{align}
\overline{X} & = - U \\
\sigma^2 & = U s 
\end{align}

\paragraph{The mean-field approximation} 

\begin{align}
\frac{\partial f_0(X)}{\partial t} & = \left[ X-\overline{X}(0)-vt \right] f_0(X) + U \int ds \, \rho(s) \left[ f_0(X-s) - f_0(X) \right] \\
\frac{\partial f_1(X)}{\partial t} & = \left[ X - \overline{X}(0) - vt \right] f_1(X) + U \int ds \, \rho(s) \left[ f_1(X-s) - f_1(X) \right] + \sqrt{\frac{f_1(X)}{N}} \eta(X)  
\end{align}

\paragraph{Problem} Derive the equation of motion for the generating functional of $f_1(X)$, defined by
\begin{align}
H[\phi(x),t] = \left\langle e^{-\int \phi(x) f(x+\overline{X}(0)+vt) \, dx } \right\rangle
\end{align}
Note that we have chosen to index the transform variable $\phi(x)$ by the \emph{relative} fitness, $x = X-\overline{X}(t)$. 

\paragraph{Problem} Derive an equation for the long-time non-extinction probability of $f_1(X,t)$, subject to the initial condition $f_1(X,0) = \frac{1}{N} \delta(X-\overline{X}(0)-x)$. The easiest way to do this is to write out the formal method of characteristics solution for $H[\phi(x),t]$ and consider the possible values of $H[\phi(x),t]$ when $t \to \infty$. Remember that we are only interested in the leading order term in $1/N$.    

\paragraph{Solution} The non-extinction probability $w(x)$ satisfies the ordinary differential equation 
\begin{align}
\label{eq:w-equation}
v \partial_x w(x) = x w + U \int ds \, \rho(s) \left[ w(x+s) - w(x) \right] - \frac{w^2}{2} 
\end{align}

\paragraph{Problem} Solve for $w(x)$ in the limit that $U=0$ and $v=0$. How does this compare with the single-locus fixation probability derived above? 

\paragraph{Solution} $w(x) = 2x$. 

\paragraph{Problem} Solve for $w(x)$ in the limit that $U=0$ and $v>0$. The easiest way to do this is to transform \eq{eq:w-equation} to a linear form using the change of variables $u=1/w$. What is the limiting form of $w(x)$ when $x \to \infty$? What about $x \to -\infty$? What is wrong with this result?

\paragraph{Solution}

\section{Appendix: The method of characteristics (special case)}

We will often need to solve partial differential initial value problems of the form
\begin{align}
\frac{\partial H}{\partial t} + f(t,z) \frac{\partial H}{\partial z} = g(t,z,H) \, , \quad H(z,0) = h(z) 
\end{align}
which can be solved using a simple version of the method of characteristics. The basic idea is this: if we look along curves that satisfy $\partial_t z = f(t,z)$, then the partial differential equation goes over to an ordinary differential equation,
\begin{align}
\frac{d H}{dt} = g(t,z(t),H) \, ,
\end{align} 
which is often much easier to solve. The only slight difficulty is that the initial condition for $z(t)$ is at the final time-point (i.e., the one you want to evaluate $H(z,t)$ at), while the initial condition for $H(t)$ is at the initial timepoint. Still, this is not too hard to deal with as long as we choose the proper notation. 

To that end, let's let $t_f$ and $z_f$ denote the point at which we want to measure $H$ at the end of the day. Then let's transform the time variable to reverse time, $\sigma = t_f - t$. This changes the initial PDE to
\begin{align}
\frac{\partial H}{\partial \sigma} - f(t_f-\sigma,z) \frac{\partial H}{\partial z} = -g(t_f-\sigma,z,H) \, , \quad H(z,t_f) = h(z) 
\end{align}
and the corresponding ODEs are
\begin{align}
\frac{\partial z}{\partial \sigma} & = - f(t_f-\sigma,z) \, , & z(0) & = z_f \\
\frac{\partial H}{\partial \sigma} & = - g(t_f-\sigma,z(\sigma),H) \, , & H(z(t_f),t_f) & = h(z(t_f)) 
\end{align}
which are naturally telescoped. The value $H(z_f,t_f)$ that we wish to find can then be obtained by evaluating $H$ at $\sigma=0$. 

\end{document}